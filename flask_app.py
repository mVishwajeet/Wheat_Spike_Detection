# -*- coding: utf-8 -*-
"""flask_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DDyeffVn9ZFxH6M0hYUN3zpJQ3rNu6w4
"""

#DETR
!pip install flask flask-cors torch torchvision
#!pip install flask-ngrok
!git clone https://github.com/facebookresearch/detr.git


#YOLO
!pip install torch torchvision
!pip install ultralytics

# Install and set up ngrok


#!pip install flask-ngrok
#!wget -q -O ngrok.zip https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.zip
#!unzip -o ngrok.zip

# Install and set up ngrok
!pip install flask
!wget -q -O ngrok.zip https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.zip
!unzip -o ngrok.zip


!sudo apt-get update && sudo apt-get install -y jq

from google.colab import drive

drive.mount('/content/drive')

# Access the file via '/content/drive/My Drive/path-to-your-model/detr_best_0.pth'

#'/content/drive/MyDrive/Models/detr_best_0.pth'


import torch
import os

# YOLOv5 model setup
# Clone YOLOv5 repo and install dependencies
if not os.path.exists("yolov5"):
    os.system("git clone https://github.com/ultralytics/yolov5.git")
    os.system("pip install -r yolov5/requirements.txt")

# Load YOLOv5 model
yolo_model_path = "/content/drive/MyDrive/Models/YOLOv5/best.pt"  # Update with your trained model path
model = torch.hub.load("ultralytics/yolov5", "custom", path=yolo_model_path)
model.eval()  # Set model to evaluation mode
print("YOLOv5 model loaded successfully!")

!pip install -r detr/requirements.txt  # Install DETR's dependencies

import os
import sys

# Add the detr directory to your Python path
detr_path = os.path.join(os.getcwd(), "detr")  # Path to the cloned detr directory
if detr_path not in sys.path:
    sys.path.insert(0, detr_path)

# Start ngrok manually
    ngrok_token = "2oyHUfuAKCRYWUQUBB9Q00EBF6C_794f3CmBqfTMTGmyoNFdC"  # Replace with your ngrok auth token
    !./ngrok authtoken $ngrok_token

from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import numpy as np
from PIL import Image
from detr.models.detr import build
import cv2
import io
import argparse


# Load DETR architecture
def get_model(num_classes=2, num_queries=100):
    # Create args for the build function
    class Args:
      # General settings
      dataset_file = "custom"  # Custom dataset
      device = "cuda" if torch.cuda.is_available() else "cpu"
      num_queries = 100  # Number of object queries
      aux_loss = False  # Auxiliary decoding losses
      masks = False  # Use masks for segmentation
      frozen_weights = None  # Path to pretrained weights for fine-tuning
      lr_backbone = 0  # Learning rate for the backbone
      dilation = False  # Use dilation in the backbone
      backbone = "resnet50"  # Backbone type
      position_embedding = "sine"  # Type of position embedding ("sine" or "learned")

      # Transformer settings
      hidden_dim = 256  # Transformer hidden dimension
      dropout = 0.1  # Dropout rate
      nheads = 8  # Number of attention heads in transformer
      dim_feedforward = 2048  # Feedforward layer dimension
      enc_layers = 6  # Number of encoder layers
      dec_layers = 6  # Number of decoder layers
      pre_norm = False  # Whether to use pre-layer normalization

      # Matcher settings
      set_cost_class = 1  # Classification cost for Hungarian matcher
      set_cost_bbox = 5  # Bounding box cost for Hungarian matcher
      set_cost_giou = 2  # Generalized IoU cost for Hungarian matcher

      # Loss coefficients
      bbox_loss_coef = 5  # Bounding box regression loss weight
      giou_loss_coef = 2  # Generalized IoU loss weight
      eos_coef = 0.1  # No-object loss weight


    args = Args()
    model, _, _ = build(args)  # The `build` function returns (model, criterion, postprocessors)
    return model

# Initialize the model
detr_model_path = "/content/drive/MyDrive/Models/Facebook's DETR/detr_best_0.pth"  # Update with the correct path
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
detr_model = get_model(num_classes=2, num_queries=100)  # Update as per your dataset

# Load the checkpoint
checkpoint = torch.load(detr_model_path, map_location=device)

# Adjust the state_dict keys if needed
if "model" in checkpoint:
    state_dict = checkpoint["model"]
else:
    state_dict = checkpoint

# Remove 'model.' prefix from keys
new_state_dict = {key.replace("model.", ""): value for key, value in state_dict.items()}

# Remove `class_embed` weights to avoid mismatched dimensions
filtered_state_dict = {key: value for key, value in new_state_dict.items() if "class_embed" not in key}

# Load weights for all layers except 'class_embed'
missing_keys, unexpected_keys = detr_model.load_state_dict(filtered_state_dict, strict=False)

# Reinitialize 'class_embed' to match the current model's `num_classes`
num_classes = 2  # Update based on your dataset
hidden_dim = 256  # Matches the model's transformer hidden dimension
detr_model.class_embed = torch.nn.Linear(hidden_dim, num_classes + 1)  # +1 for the no-object class
detr_model.class_embed.weight.data.normal_(mean=0.0, std=0.01)
detr_model.class_embed.bias.data.zero_()


detr_model.to(device)
detr_model.eval()  # Set model to evaluation mode
print("Model loaded successfully with adjusted class_embed layer!")

# === YOLOv5 Model Setup ===
yolo_model_path = "/content/drive/MyDrive/Models/YOLOv5/best.pt"
yolo_model = torch.hub.load("ultralytics/yolov5", "custom", path=yolo_model_path)
yolo_model.eval()
print("YOLOv5 model loaded successfully!")

import torchvision

from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.backbone_utils import resnet_fpn_backbone

# Create a Faster R-CNN model with a ResNet18 backbone
backbone = resnet_fpn_backbone('resnet18', pretrained=False)
faster_rcnn_model = FasterRCNN(backbone, num_classes=2)


# Load Faster R-CNN model
faster_rcnn_model_path = "/content/drive/MyDrive/Models/Faster RCNN_ResNET/faster_rcnn_resnet18.pth"
#faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2)
checkpoint = torch.load(faster_rcnn_model_path, map_location=device)
faster_rcnn_model.load_state_dict(checkpoint)
faster_rcnn_model.to(device).eval()  # Set the model to evaluation mode
print("Faster R-CNN model loaded successfully!")

def preprocess_faster_rcnn_image(image_bytes):
    # Convert bytes to a PIL image
    pil_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    # Convert PIL image to a NumPy array (OpenCV format)
    image = np.array(pil_image)
    # Normalize the image to [0, 1]
    image = image.astype(np.float32) / 255.0
    # Convert to PyTorch tensor and add batch dimension
    image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).to(device)
    return image_tensor, pil_image.size  # Return tensor and original image size


# Preprocessing function
def preprocess_image(image_bytes):
    #image = Image.open(image_bytes).convert("RGB")
    #image = np.array(image).astype(np.float32) / 255.0  # Normalize to [0, 1]
    # Convert bytes to a PIL image
    pil_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

    # Convert PIL image to a NumPy array (OpenCV format)
    image = np.array(pil_image)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)
    image /= 255.0
    return image

# Flask app setup
app = Flask(__name__)
CORS(app)








# Prediction function
def predict_detr(image, confidence_threshold=0.3):
    h, w, _ = image.shape
    image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = detr_model(image_tensor)

    pred_boxes = outputs["pred_boxes"][0].cpu().numpy()
    cx, cy, bw, bh = pred_boxes[:, 0], pred_boxes[:, 1], pred_boxes[:, 2], pred_boxes[:, 3]
    x_min = (cx - bw / 2) * w
    y_min = (cy - bh / 2) * h
    x_max = (cx + bw / 2) * w
    y_max = (cy + bh / 2) * h
    pred_boxes = np.stack([x_min+50, y_min+50, x_max+100, y_max+100], axis=-1)
    #pred_boxes = np.stack([x_min, y_min, x_max, y_max], axis=-1)


    pred_logits = outputs["pred_logits"][0].softmax(-1).cpu().numpy()

    filtered_boxes = []
    for box, scores in zip(pred_boxes, pred_logits):
        score = scores[0]  # Assuming the first class is the target
        if score > confidence_threshold:
            x_min, y_min, x_max, y_max = box.astype(int)
            if 0 <= x_min < x_max <= w and 0 <= y_min < y_max <= h:
                filtered_boxes.append([x_min, y_min, x_max, y_max])

    return filtered_boxes

# === YOLOv5 Prediction Function ===
def predict_yolo(image_bytes, conf_threshold=0.25):
    pil_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    results = yolo_model(pil_image, size=640)
    results = results.pandas().xyxy[0]
    results = results[results["confidence"] >= conf_threshold]
    boxes = results[["xmin", "ymin", "xmax", "ymax"]].values.tolist()
    return [[int(coord) for coord in box] for box in boxes]



# ===Faseter RCNN ====

def predict_faster_rcnn(image_bytes, confidence_threshold=0.5):
    # Preprocess the image
    image_tensor, (width, height) = preprocess_faster_rcnn_image(image_bytes)

    # Get predictions
    with torch.no_grad():
        outputs = faster_rcnn_model(image_tensor)

    # Extract predictions
    boxes = outputs[0]['boxes'].cpu().numpy()
    scores = outputs[0]['scores'].cpu().numpy()

    # Filter boxes by confidence threshold
    indices = scores > confidence_threshold
    boxes = boxes[indices]
    scores = scores[indices]

    # Scale boxes back to pixel coordinates
    boxes[:, 0] *= width  # x_min
    boxes[:, 1] *= height  # y_min
    boxes[:, 2] *= width  # x_max
    boxes[:, 3] *= height  # y_max

    # Clip bounding boxes to image dimensions
    boxes[:, 0] = np.clip(boxes[:, 0], 0, width)  # x_min
    boxes[:, 1] = np.clip(boxes[:, 1], 0, height)  # y_min
    boxes[:, 2] = np.clip(boxes[:, 2], 0, width)  # x_max
    boxes[:, 3] = np.clip(boxes[:, 3], 0, height)  # y_max

    # Convert to integers and return
    return [[int(coord) for coord in box] for box in boxes]




# Flask API endpoint
# === Flask Endpoints ===
@app.route("/predict", methods=["POST"])
def predict_endpoint():
    try:
        if "file" not in request.files or "model" not in request.form:
            return jsonify({"error": "Missing file or model parameter"}), 400

        file = request.files["file"]
        model_type = request.form["model"]  # 'detr', 'yolo', or 'faster_rcnn'
        image_bytes = file.read()

        if model_type == "detr":
            image = preprocess_image(image_bytes)
            boxes = predict_detr(image)
        elif model_type == "yolo":
            boxes = predict_yolo(image_bytes)
        elif model_type == "faster_rcnn":
            boxes = predict_faster_rcnn(image_bytes)
        else:
            return jsonify({"error": "Invalid model type"}), 400

        # Ensure bounding box values are converted to standard Python types
        boxes = [[int(coord) for coord in box] for box in boxes]

        print(f"Predicted boxes using {model_type}:", boxes)
        return jsonify({"boxes": boxes})

    except Exception as e:
        print(f"Error during prediction: {e}")
        return jsonify({"error": str(e)}), 500




# Start Flask app
def run_flask():
    app.run(host="0.0.0.0", port=2229)

# Start ngrok
def start_ngrok():
    ngrok_token = "2oyHUfuAKCRYWUQUBB9Q00EBF6C_794f3CmBqfTMTGmyoNFdC"
    subprocess.run(["./ngrok", "authtoken", ngrok_token], check=True)
    ngrok_process = subprocess.Popen(["./ngrok", "http", "2229"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    time.sleep(5)  # Wait for ngrok to initialize

    # Fetch public URL from ngrok API
    try:
        response = requests.get("http://localhost:4040/api/tunnels")
        public_url = response.json()['tunnels'][0]['public_url']
        print("Public URL:", public_url)
    except Exception as e:
        print("Error fetching ngrok URL:", str(e))
        public_url = None

    return ngrok_process, public_url


if __name__ == "__main__":
    import threading
    import time
    import requests
    import subprocess
    # Run Flask in a separate thread
    threading.Thread(target=run_flask).start()

    # Start ngrok and fetch public URL
    ngrok_process, public_url = start_ngrok()

    if public_url:
        print(f"Your app is available at: {public_url}")
    else:
        print("Failed to get public URL from ngrok. Check ngrok logs.")

    # Keep the script running
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("Shutting down...")
        ngrok_process.terminate()

!ps aux

